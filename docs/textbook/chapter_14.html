<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.23">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>chapter_14 – MC Coursepack</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-1fe81d0376b2c50856e68e651e390326.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-e52b01692f360e42712232c25c0c23f8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">MC Coursepack</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../getting-started/getting-started.html"> 
<span class="menu-text">Getting Started</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-r--rstudio" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">R &amp; RStudio</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-r--rstudio">    
        <li>
    <a class="dropdown-item" href="../r-and-rstudio/r-and-rstudio.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../r-and-rstudio/zotero-rstudio.html">
 <span class="dropdown-text">Zotero &amp; RStudio</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../journal/journal-student-guide.html"> 
<span class="menu-text">Weekly Journal</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../quarto/quarto-basics.html"> 
<span class="menu-text">Quarto Basics</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../workflow/weekly-workflows.html"> 
<span class="menu-text">Course Workflow</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../git/git-and-github.html"> 
<span class="menu-text">Git &amp; GitHub</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../troubleshooting/troubleshooting.html"> 
<span class="menu-text">Troubleshooting</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../reference/package-reference.html"> 
<span class="menu-text">Reference</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../textbook/index.html"> 
<span class="menu-text">Textbook</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#making-inferences" id="toc-making-inferences" class="nav-link active" data-scroll-target="#making-inferences">Making Inferences</a>
  <ul class="collapse">
  <li><a href="#the-leap-from-sample-to-population" id="toc-the-leap-from-sample-to-population" class="nav-link" data-scroll-target="#the-leap-from-sample-to-population">The Leap from Sample to Population</a></li>
  <li><a href="#the-logic-of-hypothesis-testing-a-framework-for-decision-making" id="toc-the-logic-of-hypothesis-testing-a-framework-for-decision-making" class="nav-link" data-scroll-target="#the-logic-of-hypothesis-testing-a-framework-for-decision-making">The Logic of Hypothesis Testing: A Framework for Decision-Making</a></li>
  <li><a href="#the-key-concepts-of-significance-testing" id="toc-the-key-concepts-of-significance-testing" class="nav-link" data-scroll-target="#the-key-concepts-of-significance-testing">The Key Concepts of Significance Testing</a>
  <ul class="collapse">
  <li><a href="#the-p-value-and-statistical-significance" id="toc-the-p-value-and-statistical-significance" class="nav-link" data-scroll-target="#the-p-value-and-statistical-significance">The p-value and Statistical Significance</a></li>
  <li><a href="#type-i-and-type-ii-errors-the-risks-of-decision-making" id="toc-type-i-and-type-ii-errors-the-risks-of-decision-making" class="nav-link" data-scroll-target="#type-i-and-type-ii-errors-the-risks-of-decision-making">Type I and Type II Errors: The Risks of Decision-Making</a></li>
  <li><a href="#statistical-power" id="toc-statistical-power" class="nav-link" data-scroll-target="#statistical-power">Statistical Power</a></li>
  </ul></li>
  <li><a href="#significance-vs.-meaningfulness-the-importance-of-effect-size" id="toc-significance-vs.-meaningfulness-the-importance-of-effect-size" class="nav-link" data-scroll-target="#significance-vs.-meaningfulness-the-importance-of-effect-size">Significance vs.&nbsp;Meaningfulness: The Importance of Effect Size</a></li>
  <li><a href="#a-conceptual-guide-to-common-inferential-statistical-tests" id="toc-a-conceptual-guide-to-common-inferential-statistical-tests" class="nav-link" data-scroll-target="#a-conceptual-guide-to-common-inferential-statistical-tests">A Conceptual Guide to Common Inferential Statistical Tests</a>
  <ul class="collapse">
  <li><a href="#tests-of-difference-comparing-group-means" id="toc-tests-of-difference-comparing-group-means" class="nav-link" data-scroll-target="#tests-of-difference-comparing-group-means">Tests of Difference (Comparing Group Means)</a></li>
  <li><a href="#tests-of-association-examining-relationships" id="toc-tests-of-association-examining-relationships" class="nav-link" data-scroll-target="#tests-of-association-examining-relationships">Tests of Association (Examining Relationships)</a></li>
  </ul></li>
  <li><a href="#reporting-the-results-transparency-and-precision" id="toc-reporting-the-results-transparency-and-precision" class="nav-link" data-scroll-target="#reporting-the-results-transparency-and-precision">Reporting the Results: Transparency and Precision</a></li>
  <li><a href="#conclusion-the-responsible-interpretation-of-evidence" id="toc-conclusion-the-responsible-interpretation-of-evidence" class="nav-link" data-scroll-target="#conclusion-the-responsible-interpretation-of-evidence">Conclusion: The Responsible Interpretation of Evidence</a></li>
  <li><a href="#journal-prompts" id="toc-journal-prompts" class="nav-link" data-scroll-target="#journal-prompts">Journal Prompts</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="making-inferences" class="level1">
<h1>Making Inferences</h1>
<section id="the-leap-from-sample-to-population" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="the-leap-from-sample-to-population">The Leap from Sample to Population</h2>
<p>In the previous chapter, we explored the essential first step of data analysis: describing our data. Through the tools of descriptive statistics and data visualization, we learned how to take a raw dataset and distill it into a coherent and understandable summary. We can now confidently describe the central tendency, spread, and shape of the variables within our sample. We can state the mean age of the 500 university students we surveyed, or visualize the distribution of their social media usage. This is a crucial and illuminating process, but for much of quantitative research, it is only the beginning of the journey.</p>
<p>The ultimate goal of most social scientific inquiry is not simply to describe the specific sample we have collected, but to say something meaningful about the larger, unobserved <strong>population</strong> from which that sample was drawn. We want to move from the particular to the general. We want to take the findings from our 500 students and make a reasonable claim about the media habits of all 20,000 students at the university. This is the act of <strong>statistical inference</strong>: the process of using data from a sample to draw conclusions or make educated guesses about a population. It is a logical and mathematical leap of faith, a journey from the known to the unknown.</p>
<p>How can we make this leap with any degree of confidence? How do we know if a pattern we observe in our sample—a difference between two groups or a relationship between two variables—is a “real” pattern that likely exists in the broader population, or if it is merely a fluke, a random artifact of the specific individuals who happened to end up in our sample? This is the central question that <strong>hypothesis testing</strong> is designed to answer. It is a systematic framework for making decisions under conditions of uncertainty. It is the formal process by which we use the laws of probability to evaluate the evidence from our sample and make a disciplined judgment about our research hypotheses.</p>
<p>This chapter is the culmination of our journey through the quantitative research workflow. It demystifies the logic of inferential statistics, focusing on the conceptual framework of hypothesis testing rather than on complex mathematical formulas. We will explore the core concepts that drive this process, including the crucial role of the null hypothesis, the meaning of statistical significance and the p-value, and the two types of errors we risk making in any inferential decision. Critically, we will distinguish between a finding that is statistically significant and one that is practically meaningful by introducing the essential concept of <strong>effect size</strong>. Finally, we will provide a conceptual guide to choosing the correct statistical test for your research question and offer a clear blueprint for how to report your findings transparently and responsibly.</p>
</section>
<section id="the-logic-of-hypothesis-testing-a-framework-for-decision-making" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="the-logic-of-hypothesis-testing-a-framework-for-decision-making">The Logic of Hypothesis Testing: A Framework for Decision-Making</h2>
<p>At its heart, hypothesis testing is a formal procedure for making a decision about a knowledge claim. It is a structured argument that pits two competing statements against each other: the null hypothesis and the research hypothesis.</p>
<p>As we discussed in Chapter 6, the <strong>null hypothesis (H0)</strong> is the hypothesis of “no difference” or “no relationship.” It is a statement of equality, proposing that in the population, the independent variable has no effect on the dependent variable. The <strong>research hypothesis (H1 or HA)</strong>, by contrast, is a statement of inequality, proposing that a relationship or difference does exist. The entire logical apparatus of hypothesis testing is built around a conservative and skeptical approach: we never set out to “prove” our research hypothesis. Instead, we start by assuming the null hypothesis is true and then evaluate whether the evidence from our sample is strong enough to make that assumption untenable. Our goal is to gather enough evidence to confidently <strong>reject the null hypothesis</strong>.</p>
<p>This process is designed to answer a single, fundamental question: “Is the pattern I observed in my sample data so strong and clear that it is unlikely to have occurred simply due to random chance?”</p>
<p>Imagine you conduct an experiment to test whether a new media literacy curriculum (the independent variable) improves students’ ability to identify misinformation (the dependent variable). You find that the students in your treatment group, who received the curriculum, scored an average of 10 points higher on a misinformation test than the students in the control group. This 10-point difference is the observed effect in your sample. But could this difference have happened just by luck? Is it possible that, by pure chance, you happened to randomly assign the slightly more savvy students to the treatment group? Hypothesis testing is the tool that allows us to calculate the probability of getting a 10-point difference (or an even larger one) if the curriculum actually had no effect at all (i.e., if the null hypothesis were true). If that probability is very low, we can reject the “it was just luck” explanation and conclude that the curriculum likely had a real effect.</p>
</section>
<section id="the-key-concepts-of-significance-testing" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="the-key-concepts-of-significance-testing">The Key Concepts of Significance Testing</h2>
<p>This process of evaluating probabilities is formalized through a set of key concepts that form the language of inferential statistics. Understanding these concepts is essential for both conducting and consuming quantitative research.</p>
<section id="the-p-value-and-statistical-significance" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="the-p-value-and-statistical-significance">The p-value and Statistical Significance</h3>
<p>The central output of any statistical test is the <strong>p-value</strong>. The <strong>p-value</strong> is the probability of observing your sample result (or a more extreme result) if the null hypothesis were actually true in the population. It is a measure of how surprising or unlikely your data is, assuming there is no real effect.</p>
<ul>
<li><p>A <strong>large p-value</strong> (e.g., p =.40) means that your observed result is not very surprising. There is a 40% chance of getting a result like yours even if the null hypothesis is true. This is not strong evidence against the null hypothesis.</p></li>
<li><p>A <strong>small p-value</strong> (e.g., p =.01) means that your observed result is very surprising. There is only a 1% chance of getting a result this extreme if the null hypothesis is true. This provides strong evidence against the null hypothesis.</p></li>
</ul>
<p>But how small is “small enough”? Before conducting the analysis, researchers set a threshold for this probability, a criterion for how much evidence they will require before they are willing to reject the null hypothesis. This threshold is called the <strong>alpha level (α)</strong>, or the <strong>significance level</strong>. The conventional standard in most social sciences, including communication, is to set the alpha level at <strong>.05</strong>.</p>
<p>This leads to a simple decision rule:</p>
<ul>
<li><p>If the <strong>p-value is less than or equal to the alpha level (p ≤.05)</strong>, we <strong>reject the null hypothesis</strong>. We conclude that our finding is <strong>statistically significant</strong>, meaning it is unlikely to be the result of random chance.</p></li>
<li><p>If the <strong>p-value is greater than the alpha level (p &gt;.05)</strong>, we <strong>fail to reject the null hypothesis</strong>. We conclude that our finding is not statistically significant, meaning we do not have sufficient evidence to rule out the possibility that our result is due to chance.</p></li>
</ul>
<p>It is crucial to use this precise and cautious language. We never “prove” the research hypothesis, because there is always a small probability that we are wrong. And we never “accept” the null hypothesis, because a lack of evidence for an effect is not the same as evidence for a lack of an effect.</p>
</section>
<section id="type-i-and-type-ii-errors-the-risks-of-decision-making" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="type-i-and-type-ii-errors-the-risks-of-decision-making">Type I and Type II Errors: The Risks of Decision-Making</h3>
<p>Because we are making decisions based on the incomplete information from a sample, we always run the risk of making an error. In hypothesis testing, there are two specific types of errors we can make.</p>
<ul>
<li><p><strong>Type I Error (a “False Positive”):</strong> This occurs when we <strong>reject a true null hypothesis</strong>. In other words, we conclude that there is an effect or a relationship in the population when, in reality, there is not one. Our sample data misled us, likely due to random chance. The probability of making a Type I error is directly controlled by the alpha level we set. If we set α =.05, we are accepting a 5% risk of making a Type I error.</p></li>
<li><p><strong>Type II Error (a “False Negative”):</strong> This occurs when we <strong>fail to reject a false null hypothesis</strong>. In this case, there really is an effect or relationship in the population, but our study failed to detect it. This often happens when a study has too small a sample size to detect a real but subtle effect.</p></li>
</ul>
<p>There is an inherent trade-off between these two types of errors. If we make it harder to commit a Type I error (e.g., by setting a more stringent alpha level, like α =.01), we simultaneously increase the probability of committing a Type II error. The conventional α =.05 is seen as a reasonable balance between these two risks for most social science research.</p>
</section>
<section id="statistical-power" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="statistical-power">Statistical Power</h3>
<p>Related to Type II error is the concept of <strong>statistical power</strong>. Power is the probability of correctly rejecting a false null hypothesis. In simpler terms, it is the probability that your study will detect an effect that actually exists. The conventional standard is to aim for a power of.80, which means accepting a 20% chance of committing a Type II error. Power is influenced by three main factors: the alpha level, the sample size, and the size of the effect in the population. The most direct way for a researcher to increase the power of their study is to increase their sample size.</p>
</section>
</section>
<section id="significance-vs.-meaningfulness-the-importance-of-effect-size" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="significance-vs.-meaningfulness-the-importance-of-effect-size">Significance vs.&nbsp;Meaningfulness: The Importance of Effect Size</h2>
<p>One of the most common and critical errors in interpreting quantitative research is to equate statistical significance with practical importance. A statistically significant result simply tells us that an observed effect is unlikely to be zero in the population. It does not, by itself, tell us how</p>
<p>large, strong, or meaningful that effect is.</p>
<p>This distinction is crucial because statistical significance is heavily influenced by sample size. With a very large sample, even a tiny, trivial, and practically meaningless effect can become statistically significant. For example, with a sample of 300,000 people, we might find a statistically significant difference in IQ between two groups, but that difference might be only a fraction of a single IQ point—a difference that has no real-world importance.</p>
<p>To address this, responsible researchers report not only the statistical significance of their findings but also the <strong>effect size</strong>. An <strong>effect size</strong> is a standardized statistic that measures the magnitude or strength of the effect or relationship, independent of the sample size. It answers the “so what?” question: How big is the difference? How strong is the relationship?</p>
<p>Reporting both the p-value and the effect size provides a complete picture.</p>
<ul>
<li><p>The <strong>p-value</strong> tells us about our confidence that an effect is “real” (i.e., not due to chance).</p></li>
<li><p>The <strong>effect size</strong> tells us about the practical importance or magnitude of that effect.</p></li>
</ul>
<p>A finding with a small p-value and a large effect size is the most compelling result. A finding with a small p-value but a tiny effect size may be statistically real but practically irrelevant. A finding with a large effect size but a large p-value might suggest a meaningful effect that the study was simply underpowered (due to a small sample) to detect with statistical confidence.</p>
</section>
<section id="a-conceptual-guide-to-common-inferential-statistical-tests" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="a-conceptual-guide-to-common-inferential-statistical-tests">A Conceptual Guide to Common Inferential Statistical Tests</h2>
<p>The specific statistical test a researcher uses to calculate a p-value depends on their research question, the level of measurement of their variables, and their research design. While the mathematical formulas differ, the underlying logic of hypothesis testing is the same for all of them. Here is a conceptual guide to some of the most common tests.</p>
<section id="tests-of-difference-comparing-group-means" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="tests-of-difference-comparing-group-means">Tests of Difference (Comparing Group Means)</h3>
<p><strong>t-test:</strong> This test is used to compare the means of <strong>two</strong> groups.</p>
<ul>
<li>An <strong>independent samples t-test</strong> is used when the two groups are independent of each other (e.g., an experimental group vs.&nbsp;a control group).</li>
<li>A <strong>paired samples t-test</strong> is used when the two sets of scores come from the same participants measured at two different times (e.g., a pretest and a posttest).</li>
</ul>
<p><strong>Analysis of Variance (ANOVA):</strong> This test is used to compare the means of <strong>three or more</strong> groups. An ANOVA will tell you if there is a significant difference somewhere among the group means, but it will not tell you which specific groups differ from each other. To find that out, a researcher must follow up a significant ANOVA result with <strong>post hoc tests</strong> (like the Tukey HSD test), which conduct pairwise comparisons between all the groups.</p>
</section>
<section id="tests-of-association-examining-relationships" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="tests-of-association-examining-relationships">Tests of Association (Examining Relationships)</h3>
<ul>
<li><p><strong>Chi-Square Test:</strong> This test is used to examine the relationship between two <strong>categorical (nominal)</strong> variables. It compares the observed frequencies in a contingency table to the frequencies that would be expected if there were no relationship between the variables.</p></li>
<li><p><strong>Correlation:</strong> This test measures the strength and direction of the linear relationship between two <strong>continuous (interval/ratio)</strong> variables. The result is a correlation coefficient (r) that ranges from -1.0 to +1.0.</p></li>
<li><p><strong>Regression:</strong> This is a more advanced technique used to <strong>predict</strong> the value of one continuous dependent variable from one or more independent variables. It allows researchers to assess the unique contribution of each predictor variable while controlling for the effects of the others.</p></li>
</ul>
</section>
</section>
<section id="reporting-the-results-transparency-and-precision" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="reporting-the-results-transparency-and-precision">Reporting the Results: Transparency and Precision</h2>
<p>The final stage of the research process is to communicate your findings to others. The <strong>Results</strong> section of a formal research paper is a direct, objective, and journalistic account of the outcomes of your data analysis. It should be organized around your research questions and hypotheses, presenting the evidence in a clear and logical sequence.</p>
<p>For each hypothesis or research question, a well-written results section should do the following:1</p>
<ol type="1">
<li><p><strong>Restate the hypothesis or research question</strong> being tested.</p></li>
<li><p><strong>Identify the statistical test</strong> used to evaluate it.</p></li>
<li><p><strong>Report the key descriptive statistics</strong> that are relevant to the test (e.g., the means and standard deviations for the groups being compared in a t-test).</p></li>
<li><p><strong>Report the results of the inferential test</strong> in the standard format required by the relevant style guide (such as APA). This typically includes the test statistic (e.g., t, F, r, χ²), the degrees of freedom, the obtained value of the statistic, the p-value, and the effect size.</p></li>
<li><p><strong>State in plain English whether the hypothesis was supported or not</strong> (i.e., whether the null hypothesis was rejected). Avoid the word “prove.” Instead, use cautious language like “the hypothesis was supported” or “the results are consistent with the hypothesis.”</p></li>
</ol>
<p>It is crucial to distinguish the Results section from the <strong>Discussion</strong> section. The Results section simply reports the findings without interpretation. The Discussion section is where you interpret those findings, explaining what they mean, how they relate to the literature and theory you presented in your introduction, acknowledging the study’s limitations, and suggesting directions for future research.</p>
</section>
<section id="conclusion-the-responsible-interpretation-of-evidence" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="conclusion-the-responsible-interpretation-of-evidence">Conclusion: The Responsible Interpretation of Evidence</h2>
<p>The journey from a sample to a population is the central challenge of quantitative research. Statistical inference, through the framework of hypothesis testing, provides us with a powerful and disciplined set of tools for navigating this journey. It allows us to manage uncertainty, to quantify the strength of our evidence, and to make reasonable decisions about our knowledge claims based on the laws of probability.</p>
<p>However, these tools must be used with wisdom and humility. We must remember that statistical significance is not the same as real-world importance and that our conclusions are always probabilistic, never absolute. The skills you have learned in this chapter—understanding the logic of the p-value, appreciating the importance of effect sizes, and knowing how to interpret and report statistical findings with precision—are essential for both the responsible production of new knowledge and the critical consumption of the endless stream of data-driven claims that define our modern world. They are the tools that allow us to move from simply describing what we see to making a credible and evidence-based case for what we believe to be true.</p>
</section>
<section id="journal-prompts" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="journal-prompts">Journal Prompts</h2>
<ol type="1">
<li><p>This chapter describes inference as a “leap” from sample to population. Reflect on what makes that leap trustworthy—or risky. Why is it not enough to observe a pattern in your sample? How does hypothesis testing help, and what limits remain even when your results are statistically significant?</p></li>
<li><p>Many people misunderstand the p-value as “proof.” Why is this incorrect? What does a small p-value tell us—and what does it <em>not</em> tell us? Reflect on a time you saw a research claim or news headline that leaned too heavily on the idea of “significance.” What might have been missing?</p></li>
<li><p>Imagine you find a statistically significant result in your research—but the effect size is tiny. Would you still report it? Why or why not? How do you balance statistical significance with practical or social importance? What responsibility do researchers have when communicating findings that might be misinterpreted?</p></li>
</ol>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>