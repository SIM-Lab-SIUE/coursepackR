# R `dplyr` Verbs: A Guide for Students

This document explains the core functions from the `dplyr` package. All examples use the `w144_wrangled` dataset, which you can load as follows:

```{r}
# First, make sure you have dplyr installed: install.packages("dplyr")
library(dplyr)
library(readr)
library(mccoursepack)

# Load the dataset
data_path <- system.file("extdata", "w144_teaching_dataset_v2.csv", package = "mccoursepack")
w144_data <- read_csv(data_path)
w144_wrangled <- w144_data %>% 
  mutate(
    party_simple = case_when(
      party == "Republican" ~ "Republican",
      party == "Democrat" ~ "Democrat",
      TRUE ~ "Independent/Other"
    ) %>% 
      factor(levels = c("Republican", "Democrat", "Independent/Other")),
    platform_count = (uses_facebook == "Yes") +
                     (uses_x == "Yes") +
                     (uses_instagram == "Yes") +
                     (uses_tiktok == "Yes"),
    across(
      starts_with("fb_why_"), 
      ~ if_else(. == "Yes", 1, 0),
      .names = "{.col}_n" 
    )
  ) %>% 
  mutate(
    fb_uses_count = rowSums(
      across(starts_with("fb_why_") & ends_with("_n")), 
      na.rm = TRUE
    )
  )
```

------------------------------------------------------------------------

## Rows

Verbs that principally operate on rows.

### `arrange()`

**Explanation:** This function reorders the rows in your data frame based on the values in one or more columns. The default order is ascending (A-Z, 1-10).

**Example:** Sort the data by age group.

```{r}
# Sort by the 'age_group' column in ascending order
sorted_data <- w144_wrangled %>%
  arrange(age_group)

# Print the object
print(sorted_data)
```

**Explanation:** The code above takes the original `w144_wrangled`, pipes it (`%>%`) into the `arrange()` function, and tells it to sort by the `age_group` column. Since `age_group` is text, it sorts alphabetically (e.g., "18-29" comes before "30-49").

**Practice Prompt:** How would you sort the data to see the respondents with the *most* platforms used (`platform_count`) first? (Hint: Use the `desc()` helper function inside `arrange()`).

------------------------------------------------------------------------

### `distinct()`

**Explanation:** This function is used to find and keep only the unique (or distinct) rows in your data. You can look for unique combinations across specific columns or for entire rows.

**Example:** Find all the unique combinations of `gender` and `party_simple` present in the dataset.

```{r}
distinct_combinations <- w144_wrangled %>%
  distinct(gender, party_simple)

print(distinct_combinations)
```

**Explanation:** This pipes the data into `distinct()` and specifies the columns to check for unique pairs. `dplyr` will return a new data frame containing only one row for each unique combination of `gender` and `party_simple`.

**Practice Prompt:** How would you find out how many unique age groups (`age_group`) are in the data? (Hint: You can pipe your `distinct()` result into another verb, `nrow()`, or use `n_distinct()` which you'll see later).

------------------------------------------------------------------------

### `filter()`

**Explanation:** This is one of the most powerful verbs. It allows you to keep only the rows that match a specific logical condition (e.g., `value > 10`, `column == "News"`).

**Example:** Filter the data to find all respondents who are in the "18-29" age group.

```{r}
# The == operator is used for "is equal to"
age_18_29_data <- w144_wrangled %>%
  filter(age_group == "18-29")

print(age_18_29_data)
```

**Explanation:** This code filters the `w144_wrangled` for all rows where the value in the `age_group` column is exactly `"18-29"`.

**Practice Prompt:** How would you filter for respondents who are *both* in the "18-29" age group (`age_group == "18-29"`) and use Facebook (`uses_facebook == "Yes"`)? (Hint: You use the `&` (and) operator inside your `filter()` call).

------------------------------------------------------------------------

### `slice()` `slice_head()` `slice_tail()` `slice_min()` `slice_max()` `slice_sample()`

**Explanation:** These functions subset rows based on their *position* (their integer index) or other criteria.

-   `slice()`: Selects rows by specific row numbers.
-   `slice_head()`: Selects the first `n` rows.
-   `slice_tail()`: Selects the last `n` rows.
-   `slice_min()` / `slice_max()`: Selects rows with the lowest/highest values in a column.
-   `slice_sample()`: Selects random rows.

**Example:** Select the 100th to 105th rows from the dataset.

```{r}
# Select rows by their position
sliced_data <- w144_wrangled %>%
  slice(100:105)

sliced_data
```

**Explanation:** `slice(100:105)` tells `dplyr` to keep only the rows from 100 through 105. `slice_head(n = 5)` would be a shortcut for `slice(1:5)`.

**Practice Prompt:** How would you select 10 random rows from the dataset?

------------------------------------------------------------------------

## Columns

Verbs that principally operate on columns.

### `glimpse()`

**Explanation:** This function provides a quick, transposed summary of the data frame. It's fantastic for seeing every column's name, its data type (e.g., `dbl` for numeric, `chr` for character), and the first few values.

**Example:** Get a glimpse of the dataset's structure.

```{r}
# glimpse() is often used by itself
glimpse(w144_wrangled)
```

**Explanation:** This will print a summary to your console. It's often more useful than `View()` or `head()` for large datasets with many columns, as it fits compactly and tells you the data types.

**Practice Prompt:** Run `glimpse(w144_wrangled)` and identify two columns that are `dbl` (numeric) and one column that is `chr` (character).

------------------------------------------------------------------------

### `mutate()`

**Explanation:** This verb creates new columns or modifies existing ones, while keeping all other columns.

**Example:** Create a new column `platform_count_plus_10` that is just the `platform_count` value with 10 added to it.

```{r}
new_col_data <- w144_wrangled %>%
  mutate(platform_count_plus_10 = platform_count + 10)

# Select just the relevant columns to show the change
print(new_col_data)
```

**Explanation:** `mutate()` adds a new column named `platform_count_plus_10`. The values in this column are determined by the expression on the right side of the equals sign (`platform_count + 10`).

**Practice Prompt:** Create a new column called `is_tiktok_user` that is `TRUE` if `uses_tiktok` is "Yes" and `FALSE` otherwise. (Hint: Use `is_tiktok_user = (uses_tiktok == "Yes")`).

------------------------------------------------------------------------

### `pull()`

**Explanation:** This extracts a single column from the data frame, not as a smaller data frame, but as a **vector** (which is like a list or a 1D array).

**Example:** Pull the `party_simple` column into its own vector.

```{r}
# This extracts the column as a vector
party_vector <- w144_wrangled %>%
  pull(party_simple)

print(head(party_vector))
print(str(party_vector))
```

**Explanation:** Notice the output is no longer a table. It's a single vector of data. This is useful when you want to pass the data to a function (like `mean()` or `table()`) that expects a vector, not a data frame.

**Practice Prompt:** Pull the `platform_count` column and find the average (mean) number of platforms used. (Hint: `w144_wrangled %>% pull(platform_count) %>% mean(na.rm = TRUE)`).

------------------------------------------------------------------------

### `relocate()`

**Explanation:** This function changes the order of columns. It's a convenient way to move important columns to the front of your dataset.

**Example:** Move the `age_group`, `gender`, and `party_simple` columns to the very beginning of the data frame.

```{r}
relocated_data <- w144_wrangled %>%
  relocate(age_group, gender, party_simple)

# Glimpse to see the new column order
glimpse(relocated_data)
```

**Explanation:** `relocate()` moves the specified columns to the front by default. You can also use `.before` or `.after` arguments to be more precise (e.g., `relocate(age_group, .after = QKEY)`).

**Practice Prompt:** How would you move the `QKEY` column to be *after* the `weight` column?

------------------------------------------------------------------------

### `rename()` / `rename_with()`

**Explanation:** `rename()` renames one or more columns. `rename_with()` allows you to apply a function to *all* column names (e.g., make them all lowercase).

**Example:** Rename the `gender` and `age_group` columns to `gender_renamed` and `age_category` for simplicity.

```{r}
renamed_data <- w144_wrangled %>%
  rename(gender_renamed = gender,
         age_category = age_group)

# Glimpse to see the new names
glimpse(renamed_data)
```

**Explanation:** The syntax for `rename()` is `new_name = old_name`. This is the opposite of many other tools, so be careful!

**Practice Prompt:** Rename the `party` column (which has many categories) to `political_party_full`.

------------------------------------------------------------------------

### `select()`

**Explanation:** This function subsets your data by keeping or dropping columns based on their names or types.

**Example:** Create a new, smaller data frame that only contains `QKEY`, `age_group`, `gender`, and `party_simple`.

```{r}
selected_data <- w144_wrangled %>%
  select(QKEY, age_group, gender, party_simple)

glimpse(selected_data)
```

**Explanation:** You simply list the names of the columns you want to keep. You can also use a minus sign (`-`) to drop columns (e.g., `select(-QKEY)` would keep everything *except* `QKEY`).

**Practice Prompt:** How would you select all columns that *start with* the letters "fb\_"? (Hint: Look up `select()` helpers like `starts_with()`).

------------------------------------------------------------------------

## Groups

Verbs that principally operate on groups of rows.

### `count()` / `tally()`

**Explanation:** `count()` is a powerful shortcut that groups by one or more variables and counts the number of observations (rows) in each group. `tally()` is a simpler version that just counts rows within an *existing* group (it's less common now).

**Example:** Count how many respondents are in each `party_simple` group.

```{r}
party_counts <- w144_wrangled %>%
  count(party_simple, sort = TRUE)

print(party_counts)
```

**Explanation:** This is a shortcut for `group_by(party_simple) %>% summarise(n = n())`. It automatically groups by the column(s) you provide, counts the rows, and puts the result in a new column named `n`. `sort = TRUE` sorts the results from largest to smallest.

**Practice Prompt:** Get a count of respondents by `education` level.

------------------------------------------------------------------------

### `group_by()` / `ungroup()`

**Explanation:** `group_by()` doesn't do much on its own. It adds "grouping metadata" to the data frame. Any verb you use *after* `group_by()` (like `summarise()` or `mutate()`) will be performed *on each group* separately. `ungroup()` removes this grouping metadata.

**Example:** Group the data by `party_simple`.

```{r}
# This creates a 'grouped_df'
# It looks the same, but its behavior is different
grouped_by_party <- w144_wrangled %>%
  group_by(party_simple)

print(grouped_by_party)
```

**Explanation:** As you can see, the output just says `Groups: party_simple [3]`. This tells you the data is now "primed" for a grouped operation. This leads directly to `summarise()`.

------------------------------------------------------------------------

### `summarise()` / `summarize()`

**Explanation:** This function collapses each group (created by `group_by()`) into a single summary row.

**Example:** Find the *average number of platforms used* (`platform_count`) for *each* political party (`party_simple`).

```{r}
# Find the average platform_count for each party
summary_data <- w144_wrangled %>%
  group_by(party_simple) %>%
  summarise(
    avg_platform_count = mean(platform_count, na.rm = TRUE),
    number_of_respondents = n()
  )

print(summary_data)
```

**Explanation:** This is the "group and summarize" pattern, the most common workflow in `dplyr`.

1.  `group_by(party_simple)` splits the data into groups (Republican, Democrat, Independent/Other).
2.  `summarise()` then runs calculations on *each group*.
3.  `avg_platform_count = mean(...)` creates a new column by calculating the `mean` of `platform_count` *for that group*.
4.  `number_of_respondents = n()` uses the `n()` helper to count the number of rows *in that group*.

**Practice Prompt:** Find the *maximum* `platform_count` (i.e., the highest number of platforms used) for each `gender` group. (Hint: The aggregation function is `max()`).

------------------------------------------------------------------------

## Data Frames (Joins)

Verbs that operate on two data frames. First, let's create two example data frames.

```{r}
# Create a data frame with respondent data
data_respondents <- w144_wrangled %>%
  select(QKEY, age_group, gender) %>%
  slice(1:5)

# Create a data frame with political data
data_politics <- w144_wrangled %>%
  select(QKEY, party_simple) %>%
  slice(3:7)

print(data_respondents)
print(data_politics)
```

*(This creates two small tables. `data_respondents` has rows 1-5. `data_politics` has rows 3-7. They will share `QKEY`s for rows 3, 4, and 5.)*

------------------------------------------------------------------------

### `inner_join()`

**Explanation:** Keeps only the rows that have matching keys (`QKEY` in this case) in *both* data frames.

**Example:**

```{r}
# Will find keys that are in both (rows 3, 4, 5)
inner_joined <- inner_join(data_respondents, data_politics, by = "QKEY")

print(inner_joined)
```

------------------------------------------------------------------------

### `left_join()`

**Explanation:** Keeps *all* rows from the "left" data frame (`data_respondents`) and adds data from the "right" (`data_politics`) where the keys match. If there's no match, it fills with `NA`.

**Example:**

```{r}
# Will keep all 5 rows from data_respondents
left_joined <- left_join(data_respondents, data_politics, by = "QKEY")

print(left_joined)
```

*(This will show `party_simple` for rows 3, 4, and 5, but `NA` for rows 1 and 2).*

------------------------------------------------------------------------

### `semi_join()`

**Explanation:** This is a *filtering* join. It keeps all rows from the first data frame *that have a match* in the second data frame, but it *does not* add any new columns.

**Example:** Get all respondents from `data_respondents` who are *also* in `data_politics`.

```{r}
# Will keep rows 3, 4, 5 from data_respondents
semi_joined <- semi_join(data_respondents, data_politics, by = "QKEY")

print(semi_joined)
```

------------------------------------------------------------------------

### `anti_join()`

**Explanation:** The opposite of `semi_join()`. It keeps all rows from the first data frame *that do not* have a match in the second.

**Example:** Get all respondents from `data_respondents` who are *not* in `data_politics`.

```{r}
# Will keep rows 1 and 2 from data_respondents
anti_joined <- anti_join(data_respondents, data_politics, by = "QKEY")

print(anti_joined)
```

------------------------------------------------------------------------

## Multiple Columns

### `across()`

**Explanation:** `across()` is a powerful helper function used *inside* `mutate()` or `summarise()` to apply the same function(s) to multiple columns at once.

**Example:** Get the mean of all "fb_why" numeric columns (the ones ending in `_n`).

```{r}
# We can use helpers like starts_with() and ends_with() inside across()
mean_fb_data <- w144_wrangled %>%
  summarise(
    across(starts_with("fb_why_") & ends_with("_n"), 
           ~ mean(.x, na.rm = TRUE))
  )

print(mean_fb_data)
```

**Explanation:**

-   `across(starts_with("fb_why_") & ends_with("_n"), ...)` tells `dplyr` to select all columns that start with "fb_why\_" AND end with "\_n".
-   `~ mean(.x, na.rm = TRUE)` is a "lambda" or "anonymous function". The `~` starts it, and `.x` represents *each column* being operated on. This calculates the mean for each "fb_why\_...\_n" column individually.

**Practice Prompt:** How would you use `mutate()` and `across()` to change all "tt_why\_" (TikTok-why) columns (the character ones), replacing any `"Yes"` values with `1` and all other values (like `"No"` or `NA`) with `0`? (Hint: Use `~ if_else(. == "Yes", 1, 0, 0)`).

------------------------------------------------------------------------

## Vector Functions

These are helper functions that work on individual vectors (columns).

### `case_when()`

**Explanation:** Creates a new vector by applying a set of logical conditions. It's a powerful and safe "if... else if... else" tool, perfect for `mutate()`.

**Example:** Create a new column `platform_user_type` based on `platform_count`.

```{r}
# Create a new column 'platform_user_type'
platform_data <- w144_wrangled %>%
  mutate(
    platform_user_type = case_when(
      platform_count == 0 ~ "Non-user",
      platform_count == 1 ~ "Single-platform",
      platform_count >= 2 ~ "Multi-platform",
      TRUE ~ as.character(NA) # Handle NAs
    )
  )

# Use count() to check the new column
print(count(platform_data, platform_user_type))
```

**Explanation:** `case_when()` evaluates each condition on the left of the `~` (tilde). When it finds the first `TRUE` condition, it returns the value on the right. The `TRUE ~ ...` at the end acts as a default "else" case (here, we use it to assign `NA`).

------------------------------------------------------------------------

### `if_else()`

**Explanation:** A simpler, single-condition "if... else" function. It's very strict: `if_else(condition, value_if_true, value_if_false)`.

**Example:** Create a column `facebook_user_status` that is "User" if `uses_facebook` is "Yes" and "Not User" otherwise.

```{r}
user_status_data <- w144_wrangled %>%
  mutate(
    facebook_user_status = if_else(uses_facebook == "Yes", 
                                   "User", 
                                   "Not User")
  )

print(count(user_status_data, uses_facebook, facebook_user_status))
```

------------------------------------------------------------------------

### `lag()` / `lead()`

**Explanation:** These functions "shift" a vector, allowing you to get the `lag()` (previous) or `lead()` (next) value. This is most useful *after* an `arrange()` and often inside a `group_by()`.

**Example:** Find the `QKEY` of the *previous* respondent *within the same age group*.

```{r}
# Sort by age group first!
lag_data <- w144_wrangled %>%
  arrange(age_group, QKEY) %>%
  group_by(age_group) %>%
  mutate(previous_respondent_in_group = lag(QKEY)) %>%
  ungroup() # Good practice to ungroup after mutate

print(select(lag_data, age_group, QKEY, previous_respondent_in_group), n = 10)
```

*(This will show `NA` for the* first\* respondent in each new age group, which is correct).\*

------------------------------------------------------------------------

### `n_distinct()`

**Explanation:** Counts the number of *unique* (distinct) values in a vector. It's often used inside `summarise()`.

**Example:** How many unique political parties are represented in `party_simple`?

```{r}
unique_parties <- w144_wrangled %>%
  summarise(
    num_unique_parties = n_distinct(party_simple)
  )

print(unique_parties)
```

------------------------------------------------------------------------

### `na_if()`

**Explanation:** A convenient function to convert a specific value (like `"Refused"`) to `NA` (Not Available/Missing).

**Example:** Convert all `"Refused"` values in the `party` column to `NA`.

```{r}
cleaner_data <- w144_wrangled %>%
  mutate(party_clean = na_if(party, "Refused"))

# Compare the counts
print("--- Original Counts ---")
print(count(w144_wrangled, party))
print("--- Cleaned Counts (with NA) ---")
print(count(cleaner_data, party_clean)) # Will show an NA row
```

------------------------------------------------------------------------

### `row_number()`

**Explanation:** An "ordering" function that assigns a unique number to each row (1, 2, 3...) based on an ordering. It's almost always used inside `mutate()` after `arrange()` and `group_by()`.

**Example:** Find the two respondents with the *most platforms* (highest `platform_count`) *from each political party*.

```{r}
# We arrange by the count descending first
most_platforms_in_party <- w144_wrangled %>%
  # Remove NAs in platform_count to ensure accurate ranking
  filter(!is.na(platform_count)) %>%
  arrange(desc(platform_count)) %>%
  group_by(party_simple) %>%
  mutate(rank_in_party = row_number()) %>%
  filter(rank_in_party <= 2) %>%
  select(party_simple, platform_count, rank_in_party, QKEY)
  
print(most_platforms_in_party)
```

**Explanation:**

1.  We `filter()` out `NA` values to ensure `arrange` works correctly.
2.  We `arrange()` by `platform_count` in *descending* order first.
3.  We `group_by()` political party.
4.  `mutate(rank_in_party = row_number())` gives a rank (1, 2, 3...) *restarting for each party*. Since the data is already sorted by platform count, rank 1 is the highest in that party.
5.  Finally, we `filter()` to keep only ranks 1 and 2.