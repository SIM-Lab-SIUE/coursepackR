---
title: "Lab 12: Data Wrangling"
author: "Research Methods"
format: pdf
editor: visual
---

# **Lab 12: Data Wrangling**

## **Learning Objectives**

Welcome to **data wrangling**\! This is the "mise en place" of research‚Äîthe essential prep work you do before you can get to the "cooking" (or analysis).

By the end of this lab, you will be able to:

  - Read a dataset into R.
  - **Rename and Recode** raw variables into usable formats.
  - Use the core `dplyr` verbs: `select()`, `filter()`, and `arrange()`.
  - Create new variables (columns) using `mutate()`.
  - Use `case_when()` and `if_else()` to recode data.
  - Combine multiple variables to create a **composite scale score**.
  - Answer basic descriptive questions using `group_by()` and `summarize()`.

### **Pew Research Center: Required Citation**

This lab uses a real-world dataset from the Pew Research Center. As per their Terms of Use, you must always include the following disclaimer in any work (even class assignments) that uses this data:

> "Pew Research Center bears no responsibility for the analyses or interpretations of the data presented here. The opinions expressed herein, including any implications for policy, are those of the author and not of Pew Research Center.‚Äù

## **Part 1: Setup - Loading Your Tools and Data**

Let's write some code\! In your `Lab_12.R` script (or in a code chunk like this), type the following.

**Your Workflow:**

1.  **Write** your code in the **Script Editor**.
2.  **Run** your code by pressing **`Ctrl + Enter`** (Windows) or **`Cmd + Return`** (Mac).
3.  **See** your results appear in the **Console**.
4.  **Check** your loaded data in the **Environment** pane.

### **Step 1: Load the `tidyverse` üß∞**

R's power comes from packages. The `tidyverse` is a collection of packages that makes data wrangling simple and intuitive. The `library()` function "opens the toolbox" so R can use its functions.

```{r}
library(tidyverse)
```

### **Step 2: Load Your Data ‚û°Ô∏è**

Now we'll read our data into the R **Environment**.

Most importantly, we need to *save* this data as an **object** (or "variable"). We do this using the **assignment arrow: `<-`** (a "less than" sign and a hyphen). You can think of `<-` as "gets" or "is saved as."

```{r}
library(mccoursepack)
data(ATP_W144_excerpt)
df <- ATP_W144_excerpt
```

**Check your Environment:** After running this, look at the top-right pane. You should see `df` appear.

### **Step 3: Prepare Your Data (Crucial Step\!) üßπ**

Raw survey data is often messy. In this dataset, variables have cryptic names (like `SMUSE_a_W144`) and use numbers (like `1` and `2`) instead of text (like "Yes" and "No").

Before we analyze, we must **clean** it. The following code block performs three major actions:

1.  **Rename:** It changes hard-to-read codes into simple names (e.g., changing `SMUSE_a_W144` to `uses_facebook`).
2.  **Recode Party:** It takes the numeric codes for political party (1, 2, 3) and converts them into text ("Republican", "Democrat", "Independent").
3.  **Recode "Yes/No":** It takes the numeric codes for usage (1 and 2) and converts them into "Yes" and "No".

Run this block to create a clean version of your data.

```{r}
df <- df %>%
  rename(
    party = F_PARTY_FINAL,
    age_cat = F_AGECAT,
    uses_facebook = SMUSE_a_W144,
    uses_x = SMUSE_c_W144,
    uses_instagram = SMUSE_d_W144,
    uses_tiktok = SMUSE_i_W144,
    fb_why_news = FBWHY_a_W144,
    fb_why_politics = FBWHY_b_W144,
    fb_why_culture = FBWHY_c_W144,
    fb_why_entertainment = FBWHY_d_W144,
    fb_why_friends = FBWHY_e_W144,
    fb_why_interests = FBWHY_f_W144,
    fb_why_reviews = FBWHY_g_W144
  ) %>%
  mutate(
    party = case_when(
      party == 1 ~ "Republican",
      party == 2 ~ "Democrat",
      party == 3 ~ "Independent",
      TRUE ~ "Something else"
    ),
    across(starts_with("uses_"), ~ if_else(. == 1, "Yes", "No")),
    across(starts_with("fb_why_"), ~ if_else(. %in% c(1, 2), "Yes", "No"))
  )
```

### **Step 4: Look at Your Data ‚úÖ**

Never work "blind." Always look at your data after you load and clean it.

```{r}
glimpse(df)
```

**Verify:** Look at the output in your Console. Do you see variables like `uses_facebook`? Are they now text (indicated by `<chr>`)? If so, you are ready to proceed.

## **Part 2: The Core 'Verbs' of `dplyr`**

The `tidyverse` is built on a few simple "verbs." We link these verbs together using the **pipe: `%>%`**.

The pipe `%>%` is the most important part of the `tidyverse`. It means **"AND THEN..."** It takes the data on the left and "pipes" it into the function on the right.

### **Verb 1: `select()` - Chooses COLUMNS**

`select()` is used to keep only specific columns or remove unwanted ones. The code below takes the dataframe and selects only the political party and age category columns.

```{r}
df %>%
    select(party, age_cat)
```

### **Verb 2: `filter()` - Chooses ROWS**

`filter()` is used to keep rows that match a specific logical test. The code below keeps only the rows where the `age_cat` is equal to 1 (which represents the youngest age group, 18-29).

*Note: We use a double-equals sign `==` to mean "is equal to" (a test), not a single `=` (which is for assignment).*

```{r}
df %>%
    filter(age_cat == 1)
```

### **Verb 3: `arrange()` - Sorts ROWS**

`arrange()` re-orders the rows based on a column's values. The first block below sorts the data by age (youngest to oldest). The second block sorts it in **descending** order (oldest to youngest).

```{r}
df %>%
    arrange(age_cat)

df %>%
    arrange(desc(age_cat))
```

### **Chaining Verbs Together**

The real power of the pipe comes from linking these steps together into a single chain.

The code below performs three steps in order:

1.  **Filter:** Keep only the youngest people (age category 1).
2.  **Select:** Keep only the party and age columns.
3.  **Arrange:** Sort the result alphabetically by party.

<!-- end list -->

```{r}
df %>%
    filter(age_cat == 1) %>%
    select(party, age_cat) %>%
    arrange(party)
```

This is the core of "wrangling." We will now start a new, permanent dataset called `w144_wrangled` that will hold all our new variables.

## **Part 3: Transforming Variables**

### **Task 1: Create `party_simple`**

Often, we want to simplify our data. Currently, we have Republicans, Democrats, Independents, and "Something else." Let's create a new variable that groups everyone who isn't a Democrat or Republican into a single "Independent/Other" category.

We use `mutate()` to create the new column, and `case_when()` to define the rules.

```{r}
w144_wrangled <- df %>%
    mutate(
        party_simple = case_when(
            party == "Republican" ~ "Republican",
            party == "Democrat" ~ "Democrat",
            TRUE ~ "Independent/Other"
        )
    )

# Check the result
w144_wrangled %>%
    count(party, party_simple)
```

**Check your work:** The `count()` output shows the original `party` column next to your new `party_simple` column. You should see that "Independent" and "Something else" have both been successfully re-labeled as "Independent/Other."

### **Task 2: Create `platform_count` Scale**

We want to know how many total platforms (Facebook, X, Instagram, TikTok) each person uses.

In R, `TRUE` equals `1` and `FALSE` equals `0`. We can use this to do math.
The code below checks each column (e.g., `uses_facebook == "Yes"`). If they do, it generates a `1`. If not, a `0`. We then add these four values together to get a score from 0 to 4.

```{r}
w144_wrangled <- w144_wrangled %>%
    mutate(
        platform_count = (uses_facebook == "Yes") +
            (uses_x == "Yes") +
            (uses_instagram == "Yes") +
            (uses_tiktok == "Yes")
    )

# Check the result
summary(w144_wrangled$platform_count)
```

**Check your work:** The summary should show a minimum of 0 and a maximum of 4.

## **Part 4: Create a "Reasons for Use" Scale**

This is the central task. We want to measure *how many* different reasons a person uses Facebook (e.g., for news, for politics, for friends).

We need to do this in two steps:

1.  **Recode:** Convert the "Yes" text in the `fb_why` columns into `1`s and "No" into `0`s. We use `across()` to do this to all 7 columns at once.
2.  **Sum:** Add up those new numeric columns across the row.

<!-- end list -->

```{r}
w144_wrangled <- w144_wrangled %>%
    mutate(
        # Step 4a: Create numeric (_n) versions of the columns
        across(
            starts_with("fb_why_"),
            ~ if_else(. == "Yes", 1, 0),
            .names = "{.col}_n"
        )
    ) %>%
    mutate(
        # Step 4b: Sum the new numeric columns
        fb_uses_count = rowSums(
            across(starts_with("fb_why_") & ends_with("_n")),
            na.rm = TRUE
        )
    )

# Check the result
summary(w144_wrangled$fb_uses_count)
```

**Check your work:** You should see a new variable `fb_uses_count` that ranges from 0 to 7.

## **Part 5: The Payoff - Answering Questions**

Why did we do all that? Because now we can *finally* answer interesting questions.

**Question:** What is the average number of platforms used (`platform_count`) and average number of reasons for using Facebook (`fb_uses_count`) for each political party?

We use `group_by()` to split the data by party, and `summarize()` to calculate the means.

```{r}
w144_wrangled %>%
    group_by(party_simple) %>%
    summarize(
        avg_platform_count = mean(platform_count, na.rm = TRUE),
        avg_fb_reasons = mean(fb_uses_count, na.rm = TRUE)
    ) %>%
    arrange(desc(avg_platform_count))
```

**Look at the table in your Console.** You just ran your first analysis\! You've transformed raw survey data into a clean, summary table that compares behavior across political groups.