<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.23">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>chapter_11 – MC Coursepack</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../textbook/chapter_12.html" rel="next">
<link href="../textbook/chapter_10.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-1fe81d0376b2c50856e68e651e390326.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-e52b01692f360e42712232c25c0c23f8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">MC Coursepack</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../getting-started/getting-started.html"> 
<span class="menu-text">Getting Started</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-r--rstudio" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">R &amp; RStudio</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-r--rstudio">    
        <li>
    <a class="dropdown-item" href="../r-and-rstudio/r-and-rstudio.html">
 <span class="dropdown-text">Overview</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../r-and-rstudio/zotero-rstudio.html">
 <span class="dropdown-text">Zotero &amp; RStudio</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../journal/journal-student-guide.html"> 
<span class="menu-text">Weekly Journal</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../quarto/quarto-basics.html"> 
<span class="menu-text">Quarto Basics</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../workflow/weekly-workflows.html"> 
<span class="menu-text">Course Workflow</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../git/git-and-github.html"> 
<span class="menu-text">Git &amp; GitHub</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../troubleshooting/troubleshooting.html"> 
<span class="menu-text">Troubleshooting</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../reference/package-reference.html"> 
<span class="menu-text">Reference</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../textbook/index.html"> 
<span class="menu-text">Textbook</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../textbook/chapter_11.html">Content Analysis: Manual and Automated Approaches</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      </a>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../textbook/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to the Course</span></a>
  </div>
</li>
        <li class="sidebar-item">
 <span class="menu-text">textbook/chapter_01.qmd</span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../textbook/chapter_02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">An Introduction to the Research Workflow and the Scientific Approach to Communication</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../textbook/chapter_03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Research Ethics in the Digital Age</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../textbook/chapter_04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Building on Knowledge: The Literature Review</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../textbook/chapter_05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Building on Knowledge: The Literature Review</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../textbook/chapter_06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">From Ideas to Inquiries: Developing Research Questions and Hypotheses</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../textbook/chapter_07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sampling: The Logic of Selection</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../textbook/chapter_08.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The Art of Measurement: Conceptualization and Operationalization</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../textbook/chapter_09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Survey Research: Design and Implementation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../textbook/chapter_10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Experiments and Causal Research Designs</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../textbook/chapter_11.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Content Analysis: Manual and Automated Approaches</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../textbook/chapter_12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Wrangling — Importing, Cleaning, and Transforming Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../textbook/chapter_13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Describing the Data — Descriptive Statistics and Visualization</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../textbook/chapter_14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Making Inferences — Hypothesis Testing and Reporting</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#content-analysis-manual-and-automated-approaches" id="toc-content-analysis-manual-and-automated-approaches" class="nav-link active" data-scroll-target="#content-analysis-manual-and-automated-approaches">Content Analysis: Manual and Automated Approaches</a>
  <ul class="collapse">
  <li><a href="#making-sense-of-the-symbolic-world" id="toc-making-sense-of-the-symbolic-world" class="nav-link" data-scroll-target="#making-sense-of-the-symbolic-world">Making Sense of the Symbolic World</a></li>
  <li><a href="#the-logic-and-purpose-of-content-analysis" id="toc-the-logic-and-purpose-of-content-analysis" class="nav-link" data-scroll-target="#the-logic-and-purpose-of-content-analysis">The Logic and Purpose of Content Analysis</a></li>
  <li><a href="#manual-content-analysis-a-step-by-step-guide" id="toc-manual-content-analysis-a-step-by-step-guide" class="nav-link" data-scroll-target="#manual-content-analysis-a-step-by-step-guide">Manual Content Analysis: A Step-by-Step Guide</a>
  <ul class="collapse">
  <li><a href="#step-1-formulate-the-research-question-or-hypothesis" id="toc-step-1-formulate-the-research-question-or-hypothesis" class="nav-link" data-scroll-target="#step-1-formulate-the-research-question-or-hypothesis">Step 1: Formulate the Research Question or Hypothesis</a></li>
  <li><a href="#step-2-define-the-population-of-texts" id="toc-step-2-define-the-population-of-texts" class="nav-link" data-scroll-target="#step-2-define-the-population-of-texts">Step 2: Define the Population of Texts</a></li>
  <li><a href="#step-3-select-a-sample" id="toc-step-3-select-a-sample" class="nav-link" data-scroll-target="#step-3-select-a-sample">Step 3: Select a Sample</a></li>
  <li><a href="#step-4-define-the-unit-of-analysis" id="toc-step-4-define-the-unit-of-analysis" class="nav-link" data-scroll-target="#step-4-define-the-unit-of-analysis">Step 4: Define the Unit of Analysis</a></li>
  <li><a href="#step-5-develop-the-codebook" id="toc-step-5-develop-the-codebook" class="nav-link" data-scroll-target="#step-5-develop-the-codebook">Step 5: Develop the Codebook</a></li>
  <li><a href="#step-6-train-coders-and-establish-inter-coder-reliability" id="toc-step-6-train-coders-and-establish-inter-coder-reliability" class="nav-link" data-scroll-target="#step-6-train-coders-and-establish-inter-coder-reliability">Step 6: Train Coders and Establish Inter-Coder Reliability</a></li>
  <li><a href="#step-7-code-the-full-sample" id="toc-step-7-code-the-full-sample" class="nav-link" data-scroll-target="#step-7-code-the-full-sample">Step 7: Code the Full Sample</a></li>
  <li><a href="#step-8-analyze-and-interpret-the-data" id="toc-step-8-analyze-and-interpret-the-data" class="nav-link" data-scroll-target="#step-8-analyze-and-interpret-the-data">Step 8: Analyze and Interpret the Data</a></li>
  </ul></li>
  <li><a href="#the-rise-of-automated-approaches-a-conceptual-overview" id="toc-the-rise-of-automated-approaches-a-conceptual-overview" class="nav-link" data-scroll-target="#the-rise-of-automated-approaches-a-conceptual-overview">The Rise of Automated Approaches: A Conceptual Overview</a>
  <ul class="collapse">
  <li><a href="#the-core-logic-from-words-to-numbers" id="toc-the-core-logic-from-words-to-numbers" class="nav-link" data-scroll-target="#the-core-logic-from-words-to-numbers">The Core Logic: From Words to Numbers</a></li>
  <li><a href="#key-automated-methods-a-conceptual-guide" id="toc-key-automated-methods-a-conceptual-guide" class="nav-link" data-scroll-target="#key-automated-methods-a-conceptual-guide">Key Automated Methods: A Conceptual Guide</a></li>
  </ul></li>
  <li><a href="#the-synergy-of-manual-and-automated-approaches" id="toc-the-synergy-of-manual-and-automated-approaches" class="nav-link" data-scroll-target="#the-synergy-of-manual-and-automated-approaches">The Synergy of Manual and Automated Approaches</a></li>
  <li><a href="#conclusion-a-method-for-a-message-saturated-world" id="toc-conclusion-a-method-for-a-message-saturated-world" class="nav-link" data-scroll-target="#conclusion-a-method-for-a-message-saturated-world">Conclusion: A Method for a Message-Saturated World</a></li>
  <li><a href="#journal-prompts" id="toc-journal-prompts" class="nav-link" data-scroll-target="#journal-prompts">Journal Prompts</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="chapter_11.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="content-analysis-manual-and-automated-approaches" class="level1 unnumbered">
<h1 class="unnumbered">Content Analysis: Manual and Automated Approaches</h1>
<section id="making-sense-of-the-symbolic-world" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="making-sense-of-the-symbolic-world">Making Sense of the Symbolic World</h2>
<p>We are immersed in a world of messages. From the news articles we read and the television shows we watch to the endless streams of posts, images, and videos on social media, our lives are shaped by a constant flow of communication content. This vast symbolic environment raises a host of critical questions for communication researchers: How are different social groups represented in the media? What frames are used to discuss important political issues? What are the dominant themes in online conversations about public health? How has the tone of presidential speeches changed over time?</p>
<p>Answering these questions requires a method that can systematically and objectively analyze the messages themselves. We cannot rely on casual observation or anecdotal evidence; the sheer volume and complexity of modern media would overwhelm us, and our own biases would inevitably color our conclusions. The primary research method designed for this task is <strong>content analysis</strong>. Content analysis is a research technique for the objective, systematic, and often quantitative description of the manifest and latent content of communication. It is a way of turning the texts, images, and sounds that make up our media landscape into manageable, analyzable data.</p>
<p>For decades, content analysis was a painstaking manual process, with researchers and their assistants spending countless hours meticulously coding media artifacts by hand. The digital revolution, however, has created both a challenge and an opportunity. The explosion of “big data” from online sources has made manual analysis of many contemporary communication phenomena impossible. In response, a powerful new suite of <strong>automated</strong> or <strong>computational</strong> methods has emerged, leveraging the power of computers to analyze massive datasets at a scale and speed previously unimaginable.</p>
<p>This chapter provides a comprehensive guide to both of these vital approaches. We will begin by walking through the rigorous, step-by-step process of traditional <strong>manual content analysis</strong>, from developing a codebook to ensuring the reliability of human coders. This classic approach remains the gold standard for in-depth, nuanced analysis where validity is paramount. We will then turn our attention to the conceptual logic of <strong>automated content analysis</strong>, exploring tool-agnostic principles behind key techniques like sentiment analysis and topic modeling. These computational methods offer unparalleled scale and efficiency, opening up new frontiers for communication research. Ultimately, we will see that these two approaches are not rivals, but powerful complements, and that the modern communication researcher must be equipped to understand and strategically deploy both.</p>
</section>
<section id="the-logic-and-purpose-of-content-analysis" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="the-logic-and-purpose-of-content-analysis">The Logic and Purpose of Content Analysis</h2>
<p>Content analysis is a uniquely versatile method that can be applied to virtually any form of recorded communication, including news articles, advertisements, films, social media posts, interview transcripts, and photographs. Its primary purpose is <strong>description</strong>. It is a research tool designed to produce a systematic and objective portrait of the content of communication. A study using content analysis might describe the frequency of certain behaviors in television dramas, the prevalence of different frames in news coverage of a social issue, or the types of persuasive appeals used in corporate websites.</p>
<p>It is crucial to understand what content analysis can and cannot do. It is a method for analyzing the characteristics of messages, not the intentions of the people who created them or the effects on the people who receive them. A study might find, for example, that news coverage of a particular minority group is overwhelmingly negative. This is a descriptive finding about the content. From this finding alone, we cannot definitively conclude that the journalists who produced the coverage were intentionally biased, nor can we conclude that the coverage caused prejudice in the audience. To make claims about production or effects, content analysis must be combined with other methods, such as surveys of journalists or experiments with audience members.</p>
<p>Content analysis allows researchers to examine two different levels of meaning within a text:</p>
<ul>
<li><p><strong>Manifest Content:</strong> This is the visible, surface-level, and objective content of a message. Analyzing manifest content typically involves counting the frequency of specific words, phrases, or images that are physically present and easily observable. For example, a researcher might count the number of times the word “freedom” is used in a political speech. This type of analysis is highly reliable because it requires little interpretation from the coder.</p></li>
<li><p><strong>Latent Content:</strong> This refers to the underlying, implicit, or interpretive meaning of a message. Analyzing latent content requires the coder to “read between the lines” and make a judgment about the deeper meaning being conveyed. For example, a researcher might code the overall “tone” of a news article as positive, negative, or neutral. This type of analysis can provide a richer and more nuanced understanding of a message, but it is also more subjective and presents a greater challenge for achieving reliability.</p></li>
</ul>
<p>Most content analysis projects involve a trade-off between the high reliability of manifest coding and the high validity and richness of latent coding. A well-designed study often incorporates both, using clear and systematic procedures to ensure that even the more interpretive latent coding is done as objectively as possible.</p>
</section>
<section id="manual-content-analysis-a-step-by-step-guide" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="manual-content-analysis-a-step-by-step-guide">Manual Content Analysis: A Step-by-Step Guide</h2>
<p>Manual content analysis is a rigorous, systematic process that transforms qualitative textual or visual data into quantitative numerical data through the use of human coders. While the specifics can vary, a methodologically sound manual content analysis follows a precise sequence of steps.</p>
<section id="step-1-formulate-the-research-question-or-hypothesis" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="step-1-formulate-the-research-question-or-hypothesis">Step 1: Formulate the Research Question or Hypothesis</h3>
<p>As with any research method, the process begins with a clear and focused research question or hypothesis. For a content analysis, this question must be about the characteristics of the communication content itself. For example: “Are female characters in prime-time television dramas more likely to be portrayed in domestic roles than male characters?”</p>
</section>
<section id="step-2-define-the-population-of-texts" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="step-2-define-the-population-of-texts">Step 2: Define the Population of Texts</h3>
<p>The next step is to define the universe of content you wish to study precisely. This definition must be specific and unambiguous. A population of “television shows” is too broad. A better definition would be: “All episodes of the top-10 rated one-hour, fictional dramas that aired on the four major U.S. broadcast networks (ABC, CBS, Fox, NBC) during the 2023-2024 prime-time television season.”</p>
</section>
<section id="step-3-select-a-sample" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="step-3-select-a-sample">Step 3: Select a Sample</h3>
<p>For many populations, analyzing every single text (a census) is impractical. Therefore, the researcher must select a representative sample. The sampling techniques discussed in Chapter 7 are all applicable here. A researcher might use <strong>simple random sampling</strong> to select a random subset of episodes from the population, or <strong>systematic sampling</strong> to select every nth episode. If the researcher wants to compare different networks, they might use <strong>stratified sampling</strong> to ensure a proportional number of episodes are drawn from each network.</p>
</section>
<section id="step-4-define-the-unit-of-analysis" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="step-4-define-the-unit-of-analysis">Step 4: Define the Unit of Analysis</h3>
<p>This is a critical decision point. The unit of analysis is the specific element of the text that will be individually coded and analyzed. It is the “what” or “who” that is being studied. The unit of analysis must be chosen based on the research question. In our television example, the unit of analysis could be an entire episode, a specific scene, or, most likely, each individual speaking character that appears on screen. For a study of newspapers, the unit could be the entire newspaper, a single article, a paragraph, or a photograph.</p>
</section>
<section id="step-5-develop-the-codebook" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="step-5-develop-the-codebook">Step 5: Develop the Codebook</h3>
<p>The codebook is the heart of a manual content analysis. It is the detailed instruction manual that defines the variables to be measured and specifies the categories for each variable. It is the recipe that tells the coders exactly how to translate the raw content into numerical data. A good codebook contains:</p>
<ul>
<li><p>A clear definition of each variable to be coded (e.g., “Character’s Occupation”).</p></li>
<li><p>A list of the specific categories for each variable (e.g., for “Occupation,” the categories might be 1=Doctor, 2=Lawyer, 3=Law Enforcement, 4=Homemaker, 5=Other, 9=Not Identifiable).</p></li>
<li><p>A clear operational definition for each category, with examples, to guide the coder’s decision-making.</p></li>
</ul>
<p>The categories for each variable must be <strong>mutually exclusive</strong> (a unit can only be placed into one category) and <strong>exhaustive</strong> (there is a category for every possible unit). This often requires the inclusion of an “Other” or “Not Applicable” category.</p>
</section>
<section id="step-6-train-coders-and-establish-inter-coder-reliability" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="step-6-train-coders-and-establish-inter-coder-reliability">Step 6: Train Coders and Establish Inter-Coder Reliability</h3>
<p>To ensure the objectivity of the analysis, content analysis relies on the use of multiple, independent coders. The goal is to demonstrate that the coding is not just the subjective whim of a single researcher but is a systematic process that can be reliably replicated by others. This is established through the calculation of <strong>inter-coder reliability</strong>.</p>
<p>The process involves several stages:</p>
<ol type="1">
<li><p><strong>Coder Training:</strong> The researcher holds training sessions to explain the codebook and the research project to the coders.</p></li>
<li><p><strong>Pilot Testing:</strong> All coders independently code a small, identical subset of the sample data.</p></li>
<li><p><strong>Discussion and Refinement:</strong> The researcher and coders meet to discuss their disagreements. This process often reveals ambiguities in the codebook, which is then revised and clarified.</p></li>
<li><p><strong>Formal Reliability Test:</strong> The coders then independently code a new, fresh subset of the sample (typically 10-20% of the total sample). The agreement between their coding on this subset is then calculated using a statistical index.</p></li>
</ol>
<p>While simple <strong>percent agreement</strong> is easy to calculate, it does not account for agreement that would occur by chance. Therefore, researchers use more robust statistics like <strong>Scott’s Pi</strong>, <strong>Cohen’s Kappa</strong> (for two coders), or the highly regarded <strong>Krippendorff’s Alpha</strong> (for any number of coders and levels of measurement), which all correct for chance agreement. A reliability coefficient of.80 or higher is generally considered acceptable for most research, though some fields may accept.70 for exploratory work.</p>
</section>
<section id="step-7-code-the-full-sample" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="step-7-code-the-full-sample">Step 7: Code the Full Sample</h3>
<p>Once an acceptable level of inter-coder reliability has been established, the coders can proceed to code the remainder of the sample. Disagreements on the final coding are typically resolved through discussion or by a third, senior coder.</p>
</section>
<section id="step-8-analyze-and-interpret-the-data" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="step-8-analyze-and-interpret-the-data">Step 8: Analyze and Interpret the Data</h3>
<p>The final step is to analyze the quantitative data that has been generated. This typically involves calculating descriptive statistics, such as frequencies and percentages for each category, and may involve inferential statistics, like the chi-square test, to examine the relationships between variables. The researcher then interprets these numerical findings in the context of the original research question, concluding the patterns and characteristics of the communication content.</p>
</section>
</section>
<section id="the-rise-of-automated-approaches-a-conceptual-overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="the-rise-of-automated-approaches-a-conceptual-overview">The Rise of Automated Approaches: A Conceptual Overview</h2>
<p>The meticulous, step-by-step process of manual content analysis produces high-quality, nuanced data, but its Achilles’ heel is scale. It is simply not feasible for a team of human coders to manually analyze millions of tweets, thousands of news articles, or hundreds of hours of video. The explosion of digital “big data” has necessitated the development of <strong>automated content analysis</strong> methods that leverage computational power to analyze massive datasets. While the specific tools and algorithms are constantly evolving, the underlying conceptual logic of these methods can be understood in a tool-agnostic way.</p>
<section id="the-core-logic-from-words-to-numbers" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="the-core-logic-from-words-to-numbers">The Core Logic: From Words to Numbers</h3>
<p>Automated methods work by transforming unstructured text into structured, numerical data that can be analyzed statistically. The fundamental assumption is that patterns in the use of words can reveal underlying meanings, themes, and sentiments. This transformation process begins with <strong>data preparation</strong>, or <strong>pre-processing</strong>. Before analysis, raw text must be cleaned and standardized. This typically involves a series of automated steps:</p>
<ul>
<li><p>Converting all text to a consistent case (usually lowercase).</p></li>
<li><p>Removing punctuation, numbers, and special characters (like URLs and hashtags).</p></li>
<li><p>Removing common and analytically uninteresting “stop words” (e.g., “the,” “a,” “is,” “of”).</p></li>
<li><p><strong>Stemming</strong> or <strong>Lemmatization</strong>: Reducing words to their root form to ensure that words like “run,” “runs,” and “running” are all treated as the same concept.</p></li>
</ul>
</section>
<section id="key-automated-methods-a-conceptual-guide" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="key-automated-methods-a-conceptual-guide">Key Automated Methods: A Conceptual Guide</h3>
<p>Once the text is cleaned, various algorithms can be applied to analyze it. We will focus on the conceptual logic of two of the most common approaches.</p>
<section id="dictionary-based-methods-including-sentiment-analysis" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="dictionary-based-methods-including-sentiment-analysis">Dictionary-Based Methods (including Sentiment Analysis)</h4>
<p>This is a deductive approach that mirrors the logic of a manual codebook. The researcher begins by creating or adapting a dictionary, which is a list of words where each word has been pre-assigned to a specific category. The computer then scans a new text, counts the number of words from each category in the dictionary, and calculates an overall score for the text.</p>
<p>The most common application of this method is <strong>sentiment analysis</strong>, which aims to determine the emotional tone of a text.</p>
<ul>
<li><p><strong>The Logic:</strong> A sentiment analysis dictionary contains two main lists of words: one for positive sentiment (e.g., “love,” “wonderful,” “happy,” “success”) and one for negative sentiment (e.g., “hate,” “terrible,” “sad,” “failure”).</p></li>
<li><p><strong>The Process:</strong> The algorithm reads a document (e.g., a product review) and counts the number of positive and negative words it contains. The overall sentiment of the document is then calculated based on the balance of these words. A review with many positive words and few negative words will be classified as positive.</p></li>
<li><p><strong>Strengths and Weaknesses:</strong> The strength of this approach is its speed, scalability, and high reliability. Its primary weakness is its lack of sensitivity to context. A dictionary-based approach cannot easily detect sarcasm (“This movie was so good” when the meaning is the opposite), irony, or negation (“I would not call this product a success”).</p></li>
</ul>
</section>
<section id="machine-learning-approaches-supervised-and-unsupervised" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="machine-learning-approaches-supervised-and-unsupervised">Machine Learning Approaches (Supervised and Unsupervised)</h4>
<p>These methods are more sophisticated and allow the computer to “learn” patterns from the data itself.</p>
<ul>
<li><strong>Supervised Machine Learning:</strong> This approach requires a human in the loop at the beginning. The logic is analogous to training a new coder.</li>
</ul>
<ol type="1">
<li><p><strong>Create a Training Set:</strong> A human researcher first manually codes a subset of the data (e.g., 1,000 tweets), assigning each one to a category (e.g., “Pro-Candidate,” “Anti-Candidate,” “Neutral”). This manually coded data is the “gold standard” training set.</p></li>
<li><p><strong>Train the Algorithm:</strong> The researcher then “feeds” this training data to a machine learning algorithm. The algorithm analyzes the text and learns the statistical patterns of word usage that are associated with each of the human-assigned codes. It understands, for example, which words and phrases are most predictive of a tweet being “Pro-Candidate.”</p></li>
<li><p><strong>Classify New Data</strong>: Once the algorithm is “trained,” it can be unleashed on a much larger set of new, uncoded documents, and it will automatically classify them based on the patterns it has learned.</p></li>
</ol>
<p>This approach combines the nuance of human judgment with the efficiency of computational analysis.</p>
<ul>
<li><strong>Unsupervised Machine Learning (Topic Modeling):</strong> This is an inductive approach that does not require a pre-coded training set. Its goal is to discover latent thematic structures within an extensive collection of documents.</li>
<li><strong>The Logic:</strong> The most common form of topic modeling, Latent Dirichlet Allocation (LDA), operates on a simple assumption: documents are mixtures of topics, and topics are mixtures of words.</li>
<li><strong>The Process:</strong> The algorithm analyzes the patterns of word co-occurrence across the entire corpus of documents. It identifies clusters of words that tend to appear together frequently in the same documents. These statistically-derived clusters of words are inferred to be “topics.”</li>
<li><strong>Interpretation</strong>: The algorithm does not “understand” what the topics mean. It simply outputs a set of word clusters. For example, it might identify one topic consisting of the words “election,” “candidate,” “vote,” “party,” and “poll,” and another topic consisting of “market,” “economy,” “jobs,” “stock,” and “inflation.” It is the researcher’s job to interpret these word clusters then and assign a meaningful label to each topic (e.g., “Politics” and “Economics”).</li>
</ul>
<p>Topic modeling is a powerful exploratory tool for getting a high-level overview of the major themes present in a massive, unstructured text dataset.</p>
</section>
</section>
</section>
<section id="the-synergy-of-manual-and-automated-approaches" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="the-synergy-of-manual-and-automated-approaches">The Synergy of Manual and Automated Approaches</h2>
<p>The future of content analysis lies not in a competition between manual and automated methods, but in their intelligent integration. The two approaches have complementary strengths and weaknesses. Manual coding offers high validity, nuance, and the ability to interpret complex meaning, but it is slow, expensive, and does not scale. Automated methods offer incredible speed, scale, and reliability, but they can be superficial and lack the contextual understanding of a human coder.</p>
<p>The most powerful research designs will increasingly use a hybrid approach. A researcher might use an unsupervised method like topic modeling to get a “big picture” view of a million social media posts, and then use manual, qualitative close reading to do a deep dive into the specific posts that are most representative of the most interesting topics the machine identified. Alternatively, a researcher can use manual coding to create a high-quality, “gold standard” training set of a few thousand documents, and then use that set to train a supervised machine learning classifier to code a dataset of millions accurately. This “human-in-the-loop” or “computer-assisted” approach combines the best of both worlds: the interpretive intelligence of the human researcher and the brute-force efficiency of the machine.</p>
</section>
<section id="conclusion-a-method-for-a-message-saturated-world" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="conclusion-a-method-for-a-message-saturated-world">Conclusion: A Method for a Message-Saturated World</h2>
<p>Content analysis, in both its manual and automated forms, is a foundational method for the study of mass communication. In a world increasingly saturated with media messages, the ability to systematically and objectively analyze those messages is more critical than ever. The traditional, manual approach provides a rigorous and time-tested methodology for conducting in-depth, valid analyses of communication content. Its principles of systematic sampling, careful unitizing, and reliable coding remain the bedrock of the method. The new wave of automated approaches has opened up exciting new frontiers, allowing us to analyze communication at a scale that was previously unimaginable and to discover patterns in the “big data” that shapes our digital lives.</p>
<p>The choice of which approach to use—manual, automated, or a hybrid of the two—is a strategic one that the research question, the nature and scale of the data, and the resources available must drive. By understanding the logic, procedures, strengths, and limitations of each, you will be equipped to make that choice wisely, empowering you to make a meaningful sense of our complex and ever-evolving symbolic world.</p>
</section>
<section id="journal-prompts" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="journal-prompts">Journal Prompts</h2>
<ol type="1">
<li><p>Think about a media environment you engage with regularly—TikTok, news headlines, TV dramas, YouTube comments, etc. Choose one and describe a research question that could be answered through content analysis. What would you want to measure? Would you be more interested in manifest content (what’s there) or latent content (the underlying tone or message), and why?</p></li>
<li><p>Manual coding offers nuance; automated coding provides scale. Reflect on a situation where you believe a <em>manual</em> approach would be necessary despite being more time-consuming. Then, describe another situation where <em>automation</em> would be the better choice. What do your examples reveal about the limits and strengths of each?</p></li>
<li><p>When researchers assign meaning to words or visuals, especially in latent coding or sentiment analysis, they make interpretive choices. What risks might arise from misclassifying tone, intent, or topic? Why is coder training—or model training—so essential to ensure fairness, especially when analyzing issues involving identity, politics, or public opinion?</p></li>
</ol>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../textbook/chapter_10.html" class="pagination-link" aria-label="Experiments and Causal Research Designs">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Experiments and Causal Research Designs</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../textbook/chapter_12.html" class="pagination-link" aria-label="Data Wrangling — Importing, Cleaning, and Transforming Data">
        <span class="nav-page-text">Data Wrangling — Importing, Cleaning, and Transforming Data</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>